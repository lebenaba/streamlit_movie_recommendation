{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import send_status_mail as ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some algorithms randomly initialize their parameters (sometimes with numpy), and the cross-validation folds are also randomly generated. \n",
    "If you need to reproduce your experiments multiple times, you just have to set the seed of the RNG at the beginning of your program:\"\"\"\n",
    "\n",
    "my_seed = 42\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('../data/processed/preprocessed_data_movielens.pkl')\n",
    "df.drop(columns=['title','genres','relevance','tag'], inplace=True)\n",
    "# sort columns in required order\n",
    "df = df[['userId', 'movieId', 'rating']]\n",
    "# reset index, which was nonsense after import\n",
    "df = df.reset_index().drop(columns=['index'])\n",
    "\n",
    "# Load the data into Surprise format, columns have been sorted in required order (raw user id, raw item id, rating) beforehand\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(df, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "# define sim_options to be tested\n",
    "sim_options = {\n",
    "\"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "\"min_support\": [3, 4, 5],\n",
    "\"user_based\": [False], # only item-base approach, since it is generally better suited for the task and user based would require enormous amounts of memory\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options,\n",
    "              \"k\": [20, 30, 40], # The (max) number of neighbors to take into account for aggregation\n",
    "              \"min_k\": [1, 2, 3]} # The minimum number of neighbors to take into account for aggregation\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_knnBasic.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"KNNBasic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "# define sim_options to be tested\n",
    "sim_options = {\n",
    "\"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "\"min_support\": [3, 4, 5],\n",
    "\"user_based\": [False], # only item-base approach, since it is generally better suited for the task and user based would require enormous amounts of memory\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options,\n",
    "              \"k\": [20, 30, 40], # The (max) number of neighbors to take into account for aggregation\n",
    "              \"min_k\": [1, 2, 3]} # The minimum number of neighbors to take into account for aggregation\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_knnMeans.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"KNNWithMeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline\n",
    "\n",
    "# define sim_options to be tested\n",
    "sim_options = {\n",
    "\"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "\"min_support\": [3, 4, 5],\n",
    "\"user_based\": [False], # only item-base approach, since it is generally better suited for the task and user based would require enormous amounts of memory\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options,\n",
    "              \"k\": [20, 30, 40], # The (max) number of neighbors to take into account for aggregation\n",
    "              \"min_k\": [1, 2, 3]} # The minimum number of neighbors to take into account for aggregation\n",
    "gs = GridSearchCV(KNNBaseline, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_knnBaseline.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"KNNBaseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithZScore\n",
    "\n",
    "# define sim_options to be tested\n",
    "sim_options = {\n",
    "\"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "\"min_support\": [3, 4, 5],\n",
    "\"user_based\": [False], # only item-base approach, since it is generally better suited for the task and user based would require enormous amounts of memory\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options,\n",
    "              \"k\": [20, 30, 40], # The (max) number of neighbors to take into account for aggregation\n",
    "              \"min_k\": [1, 2, 3]} # The minimum number of neighbors to take into account for aggregation\n",
    "gs = GridSearchCV(KNNWithZScore, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_knnZScore.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"KNNWithZScore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix factorization models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "# define parameters to be tested\n",
    "param_grid = {\"n_factors\":[50, 100, 150], # The number of factors. Default is ``100``.\n",
    "              \"n_epochs\": [10, 20, 30], # The number of iteration of the SGD procedure. Default is ``20``.\n",
    "              \"biased\": [True, False], # Whether to use baselines (or biases). Default is ``True``.\n",
    "              \"lr_all\": [0.002, 0.005, 0.01], # lr_all: The learning rate for all parameters. Default is ``0.005``.\n",
    "              \"reg_all\": [0.02, 0.05, 0.1], # reg_all: The regularization term for all parameters. Default is ``0.02``.\n",
    "              \"random_state\":[42]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_SVD.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"SVD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF\n",
    "\n",
    "# define parameters to be tested\n",
    "param_grid = {\"n_factors\":[10, 15, 20], # The number of factors. Default is ``15``.\n",
    "              \"n_epochs\": [20, 50, 100], # The number of iteration of the SGD procedure. Default is ``50``.\n",
    "              \"biased\": [True, False], # Whether to use baselines (or biases). Default is ``False``.\n",
    "              \"reg_pu\": [0.06, 0.08, 0.1], # The regularization term for users lambda_u. Default is ``0.06``.\n",
    "              \"reg_qi\": [0.06, 0.08, 0.1], # The regularization term for items lambda_i. Default is ``0.06``.\n",
    "              \"random_state\":[42]}\n",
    "\n",
    "gs = GridSearchCV(NMF, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_NMF.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"NMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following algorithms do not have any arguments => no GridSearchCV possible/necessary\n",
    "# NormalPredictor\n",
    "# SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "\n",
    "# define bsl_options to be tested\n",
    "bsl_options = {\"method\": [\"als\",\"sgd\"], # method can be either 'sgd' (Stochastic Gradient Descent) or 'als' (Alternating Least Squares).\n",
    "               \"n_epochs\": [5, 10, 20], # n_epochs is the number of epochs; als: default = 10, sgd: default = 20\n",
    "               'learning_rate': [0.005, 0.01, 0.02], # learning_rate is the learning rate for SGD. It's irrelevant if method is 'als'.\n",
    "               \"reg\": [0.01, 0.02, 0.05], # reg is the regularization term for 'sgd'.\n",
    "               \"reg_u\": [10, 15, 20], # The regularization parameter for users for 'als'. Default is 15.\n",
    "               \"reg_i\": [5, 10, 15]} # The regularization parameter for items for 'als'. Default is 10.\n",
    "# define parameters to be tested\n",
    "param_grid = {\"bsl_options\": bsl_options}\n",
    "\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_BaselineOnly.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"BaselineOnly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import CoClustering\n",
    "\n",
    "# define parameters to be tested\n",
    "param_grid = {\n",
    "    'n_cltr_u': [3, 5, 7, 10],  # Number of user clusters, default is 3.\n",
    "    'n_cltr_i': [3, 5, 7, 10],  # Number of item clusters, default is 3.\n",
    "    'n_epochs': [20, 30, 40],  # Number of iteration of the optimization loop. Default is ``20``.\n",
    "    'random_state': [42]  # Ensuring reproducibility\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(CoClustering, param_grid, measures=[\"rmse\", \"mse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)\n",
    "\n",
    "# save GridSearchCV object to file in models folder\n",
    "joblib.dump(gs, '../models/surp_gridsearchcv_CoClustering.pkl')\n",
    "\n",
    "# send completion message via email (server, sender, recepient according to .env)\n",
    "ssm.sendstatus(\"CoClustering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
